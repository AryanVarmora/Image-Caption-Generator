{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_cYB--vuuBRk",
        "outputId": "26724475-0aee-487f-bf73-cbe61bc756f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eoJvL-8Jt_1h",
        "outputId": "bc5deb60-964c-4536-f3a8-442d76a33bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1caad3880d3d>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Import the model definition (converted to a Python script)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipynb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_image_captioning_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Paths to processed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the parent directory of 'src' to the Python path\n",
        "current_dir = os.getcwd()  # Get the current working directory\n",
        "src_path = os.path.abspath(os.path.join(current_dir, \"src\"))  # Adjust path to 'src'\n",
        "sys.path.append(src_path)\n",
        "\n",
        "# Import the model definition (converted to a Python script)\n",
        "from model.ipynb import build_image_captioning_model\n",
        "\n",
        "# Paths to processed data\n",
        "image_features_path = \"/content/drive/MyDrive/Image-Caption-Generator/data/image_features.npy\"\n",
        "captions_path = \"/content/drive/MyDrive/Image-Caption-Generator/data/processed_captions.npy\"\n",
        "tokenizer_path = \"/content/drive/MyDrive/Image-Caption-Generator/data/tokenizer.pkl\"\n",
        "\n",
        "# Constants\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Load data\n",
        "def load_data():\n",
        "    image_features = np.load(image_features_path, allow_pickle=True).item()\n",
        "    captions = np.load(captions_path, allow_pickle=True).item()\n",
        "    return image_features, captions\n",
        "\n",
        "# Data generator\n",
        "def data_generator(image_features, captions, tokenizer, max_caption_length, batch_size):\n",
        "    while True:\n",
        "        image_inputs, caption_inputs, targets = [], [], []\n",
        "        for image_id, caption_set in captions.items():\n",
        "            for caption in caption_set:\n",
        "                input_seq = caption[:-1]  # Exclude the last word for inputs\n",
        "                target_seq = caption[1:]  # Shift the sequence by one for targets\n",
        "\n",
        "                input_seq_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                    [input_seq], maxlen=max_caption_length, padding=\"post\"\n",
        "                )[0]\n",
        "                target_seq_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                    [target_seq], maxlen=max_caption_length, padding=\"post\"\n",
        "                )[0]\n",
        "\n",
        "                image_inputs.append(image_features[image_id])\n",
        "                caption_inputs.append(input_seq_padded)\n",
        "                targets.append(target_seq_padded)\n",
        "\n",
        "                if len(image_inputs) == batch_size:\n",
        "                    yield (\n",
        "                        (np.array(image_inputs), np.array(caption_inputs)),\n",
        "                        np.array(targets),\n",
        "                    )\n",
        "                    image_inputs, caption_inputs, targets = [], [], []\n",
        "\n",
        "print(\"Building model...\")\n",
        "model = build_image_captioning_model()\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "with open(tokenizer_path, \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Include padding token\n",
        "max_caption_length = 35  # Match preprocessing\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "image_features, captions = load_data()\n",
        "\n",
        "# Create the dataset\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(image_features, captions, tokenizer, max_caption_length, BATCH_SIZE),\n",
        "    output_signature=(\n",
        "        (\n",
        "            tf.TensorSpec(shape=(BATCH_SIZE, 2048), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(BATCH_SIZE, max_caption_length), dtype=tf.int32),\n",
        "        ),\n",
        "        tf.TensorSpec(shape=(BATCH_SIZE, max_caption_length), dtype=tf.int32),\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "steps_per_epoch = sum(len(captions[image]) * (len(captions[image][0]) - 1) for image in captions) // BATCH_SIZE\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"model_checkpoint.keras\", save_best_only=True, monitor=\"loss\", mode=\"min\"\n",
        ")\n",
        "early_stopping = EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "model.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[checkpoint, early_stopping],\n",
        ")\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}